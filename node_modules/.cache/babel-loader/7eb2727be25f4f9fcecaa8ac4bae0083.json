{"ast":null,"code":"'use strict';\n\nvar _classCallCheck = require(\"C:\\\\Users\\\\Ankit Anand\\\\Desktop\\\\New folder (2)\\\\Our_Storage_Dapp\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/classCallCheck\");\nvar _createClass = require(\"C:\\\\Users\\\\Ankit Anand\\\\Desktop\\\\New folder (2)\\\\Our_Storage_Dapp\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/createClass\");\nObject.defineProperty(exports, '__esModule', {\n  value: true\n});\nvar common = require('./common.js');\nvar token = require('./token.js');\nvar jump = require('./jump.js');\nvar defaultDecodeOptions = {\n  strict: false,\n  allowIndefinite: true,\n  allowUndefined: true,\n  allowBigInt: true\n};\nvar Tokeniser = /*#__PURE__*/function () {\n  function Tokeniser(data) {\n    var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    _classCallCheck(this, Tokeniser);\n    this.pos = 0;\n    this.data = data;\n    this.options = options;\n  }\n  _createClass(Tokeniser, [{\n    key: \"done\",\n    value: function done() {\n      return this.pos >= this.data.length;\n    }\n  }, {\n    key: \"next\",\n    value: function next() {\n      var byt = this.data[this.pos];\n      var token = jump.quick[byt];\n      if (token === undefined) {\n        var decoder = jump.jump[byt];\n        if (!decoder) {\n          throw new Error(\"\".concat(common.decodeErrPrefix, \" no decoder for major type \").concat(byt >>> 5, \" (byte 0x\").concat(byt.toString(16).padStart(2, '0'), \")\"));\n        }\n        var minor = byt & 31;\n        token = decoder(this.data, this.pos, minor, this.options);\n      }\n      this.pos += token.encodedLength;\n      return token;\n    }\n  }]);\n  return Tokeniser;\n}();\nvar DONE = Symbol.for('DONE');\nvar BREAK = Symbol.for('BREAK');\nfunction tokenToArray(token, tokeniser, options) {\n  var arr = [];\n  for (var i = 0; i < token.value; i++) {\n    var value = tokensToObject(tokeniser, options);\n    if (value === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(\"\".concat(common.decodeErrPrefix, \" got unexpected break to lengthed array\"));\n    }\n    if (value === DONE) {\n      throw new Error(\"\".concat(common.decodeErrPrefix, \" found array but not enough entries (got \").concat(i, \", expected \").concat(token.value, \")\"));\n    }\n    arr[i] = value;\n  }\n  return arr;\n}\nfunction tokenToMap(token, tokeniser, options) {\n  var useMaps = options.useMaps === true;\n  var obj = useMaps ? undefined : {};\n  var m = useMaps ? new Map() : undefined;\n  for (var i = 0; i < token.value; i++) {\n    var key = tokensToObject(tokeniser, options);\n    if (key === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(\"\".concat(common.decodeErrPrefix, \" got unexpected break to lengthed map\"));\n    }\n    if (key === DONE) {\n      throw new Error(\"\".concat(common.decodeErrPrefix, \" found map but not enough entries (got \").concat(i, \" [no key], expected \").concat(token.value, \")\"));\n    }\n    if (useMaps !== true && typeof key !== 'string') {\n      throw new Error(\"\".concat(common.decodeErrPrefix, \" non-string keys not supported (got \").concat(typeof key, \")\"));\n    }\n    var value = tokensToObject(tokeniser, options);\n    if (value === DONE) {\n      throw new Error(\"\".concat(common.decodeErrPrefix, \" found map but not enough entries (got \").concat(i, \" [no value], expected \").concat(token.value, \")\"));\n    }\n    if (useMaps) {\n      m.set(key, value);\n    } else {\n      obj[key] = value;\n    }\n  }\n  return useMaps ? m : obj;\n}\nfunction tokensToObject(tokeniser, options) {\n  if (tokeniser.done()) {\n    return DONE;\n  }\n  var token$1 = tokeniser.next();\n  if (token$1.type === token.Type.break) {\n    return BREAK;\n  }\n  if (token$1.type.terminal) {\n    return token$1.value;\n  }\n  if (token$1.type === token.Type.array) {\n    return tokenToArray(token$1, tokeniser, options);\n  }\n  if (token$1.type === token.Type.map) {\n    return tokenToMap(token$1, tokeniser, options);\n  }\n  if (token$1.type === token.Type.tag) {\n    if (options.tags && typeof options.tags[token$1.value] === 'function') {\n      var tagged = tokensToObject(tokeniser, options);\n      return options.tags[token$1.value](tagged);\n    }\n    throw new Error(\"\".concat(common.decodeErrPrefix, \" tag not supported (\").concat(token$1.value, \")\"));\n  }\n  throw new Error('unsupported');\n}\nfunction decode(data, options) {\n  if (!(data instanceof Uint8Array)) {\n    throw new Error(\"\".concat(common.decodeErrPrefix, \" data to decode must be a Uint8Array\"));\n  }\n  options = Object.assign({}, defaultDecodeOptions, options);\n  var tokeniser = options.tokenizer || new Tokeniser(data, options);\n  var decoded = tokensToObject(tokeniser, options);\n  if (decoded === DONE) {\n    throw new Error(\"\".concat(common.decodeErrPrefix, \" did not find any content to decode\"));\n  }\n  if (decoded === BREAK) {\n    throw new Error(\"\".concat(common.decodeErrPrefix, \" got unexpected break\"));\n  }\n  if (!tokeniser.done()) {\n    throw new Error(\"\".concat(common.decodeErrPrefix, \" too many terminals, data makes no sense\"));\n  }\n  return decoded;\n}\nexports.Tokeniser = Tokeniser;\nexports.decode = decode;\nexports.tokensToObject = tokensToObject;","map":null,"metadata":{},"sourceType":"script"}